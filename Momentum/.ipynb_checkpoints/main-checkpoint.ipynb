{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.DataProcessor import *\n",
    "from Modules.ForwardLayers import *\n",
    "from Modules.BackwardLayers import *\n",
    "from Modules.Loss import *\n",
    "from Modules.Trainner import *\n",
    "from Modules.optim import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Fetching the datasets\n",
    "data = get_CIFAR10_data()\n",
    "\n",
    "# Printing the dimensions and shape of the datasets\n",
    "for k, v in data.items():\n",
    "    print ('%s: ' % k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the Convolutional Neural Network\n",
    "\n",
    "class ConvNet(object):\n",
    "    \"\"\" Architecture: conv - relu - 2x2 max pool - affine - relu - affine - softmax\"\"\"\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_dim=(3, 32, 32), num_filters=32, filter_size=7,\n",
    "                 hidden_dim=100, num_classes=10, weight_scale=1e-3, reg=0.0,\n",
    "                 dtype=np.float32, use_batchnorm=False):\n",
    "        \n",
    "        # Initialization\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.params = {}  # Dictionary to pack weights and bias\n",
    "        self.reg = reg\n",
    "        self.dtype = dtype\n",
    "        # Size of the input\n",
    "        C, H, W = input_dim\n",
    "        # Size of filters\n",
    "        F = num_filters\n",
    "        filter_height = filter_size\n",
    "        filter_width = filter_size\n",
    "        # Stride\n",
    "        stride_conv = 1\n",
    "        # Pad                                          \n",
    "        P = (filter_size - 1) / 2\n",
    "        \n",
    "        # Output Activations size\n",
    "        Hc =((H + 2 * P - filter_height) / stride_conv )+ 1\n",
    "        Wc = ((W + 2 * P - filter_width) / stride_conv) + 1\n",
    "        \n",
    "        # Initializing the weights with a given standard deviations\n",
    "        W1 = weight_scale * np.random.randn(F, C, filter_height, filter_width)\n",
    "        # Initialzing the bias\n",
    "        b1 = np.zeros(F)\n",
    "        \n",
    "        # Parameters for pooling\n",
    "        width_pool = 2\n",
    "        height_pool = 2\n",
    "        stride_pool = 2\n",
    "        Hp = ((Hc - height_pool) / stride_pool) + 1\n",
    "        Wp = ((Wc - width_pool) / stride_pool )+ 1\n",
    "        \n",
    "        Hp=int(Hp)  # Type casting into int\n",
    "        Wp=int(Wp)\n",
    "        \n",
    "        # Hidden Affine layer Parameters\n",
    "        Hh = hidden_dim\n",
    "        W2 = weight_scale * np.random.randn(F * Hp * Wp, Hh)\n",
    "        b2 = np.zeros(Hh)\n",
    "        \n",
    "        # Output affine layer Parameters\n",
    "        Hc = num_classes\n",
    "        W3 = weight_scale * np.random.randn(Hh, Hc)\n",
    "        b3 = np.zeros(Hc)\n",
    "\n",
    "        self.params.update({'W1': W1,\n",
    "                            'W2': W2,      # Packing all weights into a dictionary \n",
    "                            'W3': W3,\n",
    "                            'b1': b1,\n",
    "                            'b2': b2,\n",
    "                            'b3': b3})\n",
    "        \n",
    "        for k, v in self.params.items():     # Type conversion\n",
    "            self.params[k] = v.astype(dtype)   \n",
    "    \n",
    "    def loss(self, X, y=None):\n",
    "        \n",
    "        \"\"\"Evaluate loss and gradient for the three-layer convolutional network.\"\"\"\n",
    "\n",
    "        \n",
    "        X = X.astype(self.dtype) # Type casting into suitable type for numpy\n",
    "        \n",
    "        mode = 'test' if y is None else 'train' # Setting mode- Test/Train\n",
    "\n",
    "        N = X.shape[0]                        \n",
    "\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        W3, b3 = self.params['W3'], self.params['b3']\n",
    "\n",
    "        # pass conv_param to the forward pass for the convolutional layer\n",
    "        filter_size = W1.shape[2]\n",
    "        conv_param = {'stride': 1, 'pad':(filter_size-1)/2} \n",
    "\n",
    "        # pass pool_param to the forward pass for the max-pooling layer\n",
    "        pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "        scores = None\n",
    "       \n",
    "        # Forward into the conv layer\n",
    "        x = X\n",
    "        w = W1\n",
    "        b = b1\n",
    "        \n",
    "\n",
    "        \n",
    "        conv_layer, cache_conv_layer = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "\n",
    "        N, F, Hp, Wp = conv_layer.shape  # output shape\n",
    "        \n",
    "\n",
    "\n",
    "        # Forward into the hidden layer\n",
    "        \n",
    "        x = conv_layer.reshape((N, F * Hp * Wp))\n",
    "        w = W2\n",
    "        b = b2 \n",
    "        \n",
    "\n",
    "        hidden_layer, cache_hidden_layer = affine_relu_forward(x, w, b)\n",
    "        N, Hh = hidden_layer.shape\n",
    "        \n",
    "\n",
    "\n",
    "        # Forward into the linear output layer\n",
    "       \n",
    "        x = hidden_layer\n",
    "        w = W3\n",
    "        b = b3\n",
    "        \n",
    "\n",
    "        scores, cache_scores = affine_forward(x, w, b)\n",
    "\n",
    "\n",
    "        if y is None:               # If it is a test, return the scores\n",
    "            return scores\n",
    "\n",
    "        loss, grads = 0, {}\n",
    "       \n",
    "        data_loss, dscores = softmax_loss(scores, y)\n",
    "        reg_loss = 0.5 * self.reg * np.sum(W1**2)\n",
    "        reg_loss += 0.5 * self.reg * np.sum(W2**2)\n",
    "        reg_loss += 0.5 * self.reg * np.sum(W3**2)\n",
    "        loss = data_loss + reg_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        grads = {}\n",
    "        # Backprop into output layer\n",
    "        dx3, dW3, db3 = affine_backward(dscores, cache_scores)\n",
    "        dW3 += self.reg * W3\n",
    "\n",
    "        # Backprop into first layer\n",
    "        dx2, dW2, db2 = affine_relu_backward(dx3, cache_hidden_layer)\n",
    "\n",
    "        dW2 += self.reg * W2\n",
    "\n",
    "        # Backprop into the conv layer\n",
    "        dx2 = dx2.reshape(N, F, Hp, Wp)\n",
    "        dx, dW1, db1 = conv_relu_pool_backward(dx2, cache_conv_layer)\n",
    "        dW1 += self.reg * W1\n",
    "\n",
    "        grads.update({'W1': dW1,\n",
    "                      'b1': db1,\n",
    "                      'W2': dW2,\n",
    "                      'b2': db2,\n",
    "                      'W3': dW3,\n",
    "                      'b3': db3})\n",
    "\n",
    "      \n",
    "        return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 1 / 30) loss: 2.336021\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 0 / 15) train acc: 0.140000; val_acc: 0.106000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 2 / 30) loss: 2.247839\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 1 / 15) train acc: 0.200000; val_acc: 0.128000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 3 / 30) loss: 2.158086\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 4 / 30) loss: 2.026738\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 2 / 15) train acc: 0.250000; val_acc: 0.160000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 5 / 30) loss: 2.202894\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 6 / 30) loss: 2.286804\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 3 / 15) train acc: 0.330000; val_acc: 0.176000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 7 / 30) loss: 2.046010\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 8 / 30) loss: 2.005696\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 4 / 15) train acc: 0.450000; val_acc: 0.175000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 9 / 30) loss: 1.689687\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 10 / 30) loss: 1.803974\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 5 / 15) train acc: 0.540000; val_acc: 0.176000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 11 / 30) loss: 1.711498\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 12 / 30) loss: 1.578520\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 6 / 15) train acc: 0.550000; val_acc: 0.179000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 13 / 30) loss: 1.489721\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 14 / 30) loss: 1.348242\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 7 / 15) train acc: 0.660000; val_acc: 0.183000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 15 / 30) loss: 1.362631\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 16 / 30) loss: 1.050980\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 8 / 15) train acc: 0.670000; val_acc: 0.194000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 17 / 30) loss: 1.120804\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 18 / 30) loss: 1.112762\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 9 / 15) train acc: 0.720000; val_acc: 0.204000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 19 / 30) loss: 0.841276\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 20 / 30) loss: 0.996551\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 10 / 15) train acc: 0.790000; val_acc: 0.205000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 21 / 30) loss: 0.531573\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 22 / 30) loss: 0.653730\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 11 / 15) train acc: 0.870000; val_acc: 0.190000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 23 / 30) loss: 0.658652\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 24 / 30) loss: 0.763021\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 12 / 15) train acc: 0.820000; val_acc: 0.181000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 25 / 30) loss: 0.532341\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 26 / 30) loss: 0.516343\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 13 / 15) train acc: 0.900000; val_acc: 0.203000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 27 / 30) loss: 0.582436\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 28 / 30) loss: 0.385906\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 14 / 15) train acc: 0.870000; val_acc: 0.210000\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 29 / 30) loss: 0.255436\n",
      "50 (50, 32, 16, 16)\n",
      "(50, 100)\n",
      "(Iteration 30 / 30) loss: 0.317854\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "100 (100, 32, 16, 16)\n",
      "(100, 100)\n",
      "(Epoch 15 / 15) train acc: 0.920000; val_acc: 0.205000\n"
     ]
    }
   ],
   "source": [
    "# Object of Convolutional Neural Network\n",
    "model = ConvNet(weight_scale=1e-2)\n",
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=15, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "\n",
    "solver.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 32, 32)\n",
      "1 (1, 32, 16, 16)\n",
      "(1, 100)\n",
      "[[ 1.3289769  -1.6131816  -1.2976675   0.19625357  2.8078105   1.05697\n",
      "  -4.2801557  11.192909   -8.704842    3.5583096 ]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "img = Image.open(\"D:/horse.jpg\",\"r\")\n",
    "img.load()\n",
    "img = img.resize((32, 32))\n",
    "data = np.asarray( img, dtype=\"int32\" )\n",
    "\n",
    "data = np.expand_dims(data,axis=0)\n",
    "data=data.transpose(0,3,1,2)\n",
    "print (data.shape)\n",
    "scores=model.loss(data)\n",
    "\n",
    "print (scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
